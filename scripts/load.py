"""
√âTAPE 3: CHARGEMENT
Charge les donn√©es transform√©es dans MySQL
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import logging
import time
import argparse
from sqlalchemy import text
from config.config import (
    PIPELINE_CONFIG, validate_config, 
    get_db_engine, get_db_connection
)

# Configuration du logging
logger = logging.getLogger(__name__)


def log_execution(connection, step, status, rows=0, error=None, duration=None):
    """Log l'ex√©cution dans la base de donn√©es"""
    try:
        query = text("""
            INSERT INTO pipeline_execution_log 
            (pipeline_step, status, rows_processed, error_message, duration_seconds)
            VALUES (:step, :status, :rows, :error, :duration)
        """)
        connection.execute(query, {
            'step': step,
            'status': status,
            'rows': rows,
            'error': error,
            'duration': duration
        })
        connection.commit()
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Impossible de logger dans la DB: {e}")


def load_csv_data(file_path: str) -> pd.DataFrame:
    """
    Charge les donn√©es depuis un fichier CSV
    
    Args:
        file_path: Chemin du fichier CSV
    
    Returns:
        DataFrame avec les donn√©es
    """
    logger.info(f"üìÇ Chargement: {file_path}")
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Fichier introuvable: {file_path}")
    
    df = pd.read_csv(file_path)
    logger.info(f"‚úÖ {len(df)} enregistrements charg√©s")
    
    return df


def load_daily_rates(df: pd.DataFrame, engine, connection) -> int:
    """
    Charge les taux quotidiens dans fact_fx_rates_daily
    
    Args:
        df: DataFrame avec les cross-pairs
        engine: SQLAlchemy engine
        connection: SQLAlchemy connection
    
    Returns:
        Nombre de lignes ins√©r√©es
    """
    start_time = time.time()
    logger.info(f"üíæ Chargement de {len(df)} taux quotidiens...")
    
    # Convertir rate_date en format date
    if df['rate_date'].dtype == 'object':
        df['rate_date'] = pd.to_datetime(df['rate_date']).dt.date
    
    rows_inserted = 0
    rows_updated = 0
    
    try:
        # Tentative d'insertion directe (plus rapide)
        df.to_sql(
            'fact_fx_rates_daily',
            con=engine,
            if_exists='append',
            index=False,
            method='multi',
            chunksize=1000
        )
        rows_inserted = len(df)
        logger.info(f"‚úÖ {rows_inserted} taux ins√©r√©s directement")
        
    except Exception as e:
        # En cas de doublons, utiliser UPSERT
        logger.warning(f"‚ö†Ô∏è Insertion directe √©chou√©e, utilisation de UPSERT")
        logger.debug(f"Erreur: {e}")
        
        for _, row in df.iterrows():
            query = text("""
                INSERT INTO fact_fx_rates_daily 
                (rate_date, base_currency, quote_currency, exchange_rate, source)
                VALUES (:date, :base, :quote, :rate, 'Frankfurter')
                ON DUPLICATE KEY UPDATE 
                    exchange_rate = VALUES(exchange_rate),
                    updated_at = CURRENT_TIMESTAMP
            """)
            
            result = connection.execute(query, {
                'date': row['rate_date'],
                'base': row['base_currency'],
                'quote': row['quote_currency'],
                'rate': row['exchange_rate']
            })
            
            if result.rowcount == 1:
                rows_inserted += 1
            else:
                rows_updated += 1
        
        connection.commit()
        logger.info(f"‚úÖ UPSERT termin√©: {rows_inserted} ins√©r√©s, {rows_updated} mis √† jour")
    
    duration = int(time.time() - start_time)
    logger.info(f"‚è±Ô∏è  Dur√©e: {duration}s")
    
    return rows_inserted + rows_updated, duration


def load_ytd_metrics(df: pd.DataFrame, engine, connection) -> int:
    """
    Charge les m√©triques YTD dans fact_fx_rates_ytd
    
    Args:
        df: DataFrame avec les m√©triques YTD
        engine: SQLAlchemy engine
        connection: SQLAlchemy connection
    
    Returns:
        Nombre de lignes ins√©r√©es
    """
    start_time = time.time()
    logger.info(f"üíæ Chargement de {len(df)} m√©triques YTD...")
    
    # Convertir rate_date en format date
    if df['rate_date'].dtype == 'object':
        df['rate_date'] = pd.to_datetime(df['rate_date']).dt.date
    
    # Supprimer les anciennes donn√©es YTD pour les dates concern√©es
    dates = df['rate_date'].unique()
    logger.info(f"üóëÔ∏è  Suppression des anciennes donn√©es YTD pour {len(dates)} dates")
    
    for d in dates:
        query = text("DELETE FROM fact_fx_rates_ytd WHERE rate_date = :date")
        connection.execute(query, {'date': d})
    
    connection.commit()
    
    # Insertion des nouvelles donn√©es
    df.to_sql(
        'fact_fx_rates_ytd',
        con=engine,
        if_exists='append',
        index=False,
        method='multi',
        chunksize=1000
    )
    
    duration = int(time.time() - start_time)
    logger.info(f"‚úÖ {len(df)} m√©triques YTD ins√©r√©es")
    logger.info(f"‚è±Ô∏è  Dur√©e: {duration}s")
    
    return len(df), duration


def verify_load(connection):
    """
    V√©rifie que les donn√©es ont √©t√© correctement charg√©es
    
    Args:
        connection: SQLAlchemy connection
    """
    logger.info("\nüîç V√©rification du chargement...")
    
    # Compter les taux quotidiens
    query = text("SELECT COUNT(*) as count FROM fact_fx_rates_daily")
    result = connection.execute(query).fetchone()
    daily_count = result[0]
    logger.info(f"üìä Taux quotidiens en base: {daily_count:,}")
    
    # Compter les m√©triques YTD
    query = text("SELECT COUNT(*) as count FROM fact_fx_rates_ytd")
    result = connection.execute(query).fetchone()
    ytd_count = result[0]
    logger.info(f"üìà M√©triques YTD en base: {ytd_count:,}")
    
    # Date la plus r√©cente
    query = text("SELECT MAX(rate_date) as max_date FROM fact_fx_rates_daily")
    result = connection.execute(query).fetchone()
    max_date = result[0]
    logger.info(f"üìÖ Derni√®re date disponible: {max_date}")
    
    # Nombre de paires de devises
    query = text("""
        SELECT COUNT(DISTINCT CONCAT(base_currency, '/', quote_currency)) as pair_count 
        FROM fact_fx_rates_daily
    """)
    result = connection.execute(query).fetchone()
    pair_count = result[0]
    logger.info(f"üí± Paires de devises: {pair_count}")


def main(input_cross_path: str = None, input_ytd_path: str = None):
    """
    Fonction principale de chargement
    
    Args:
        input_cross_path: Chemin du CSV des cross-pairs
        input_ytd_path: Chemin du CSV des m√©triques YTD
    """
    logger.info("=" * 60)
    logger.info("üíæ √âTAPE 3: CHARGEMENT DANS MYSQL")
    logger.info("=" * 60)
    
    engine = None
    connection = None
    total_rows = 0
    total_duration = 0
    
    try:
        # Validation de la config
        validate_config()
        
        # Param√®tres par d√©faut
        if input_cross_path is None:
            input_cross_path = PIPELINE_CONFIG['transform_output']
        if input_ytd_path is None:
            input_ytd_path = PIPELINE_CONFIG['ytd_output']
        
        logger.info(f"üìÇ Cross-pairs: {input_cross_path}")
        logger.info(f"üìÇ M√©triques YTD: {input_ytd_path}")
        
        # Connexion DB
        engine = get_db_engine()
        connection = get_db_connection()
        logger.info("‚úÖ Connexion √† MySQL √©tablie")
        
        log_execution(connection, 'load', 'running')
        
        # Chargement des cross-pairs
        logger.info("\n[3.1] Chargement des taux quotidiens")
        df_cross = load_csv_data(input_cross_path)
        rows_daily, duration_daily = load_daily_rates(df_cross, engine, connection)
        total_rows += rows_daily
        total_duration += duration_daily
        
        # Chargement des m√©triques YTD
        logger.info("\n[3.2] Chargement des m√©triques YTD")
        df_ytd = load_csv_data(input_ytd_path)
        rows_ytd, duration_ytd = load_ytd_metrics(df_ytd, engine, connection)
        total_rows += rows_ytd
        total_duration += duration_ytd
        
        # V√©rification
        verify_load(connection)
        
        # Log succ√®s
        log_execution(connection, 'load', 'success', total_rows, duration=total_duration)
        
        logger.info("\n" + "=" * 60)
        logger.info("‚úÖ CHARGEMENT TERMIN√â AVEC SUCC√àS")
        logger.info(f"üìä Total des lignes: {total_rows:,}")
        logger.info(f"‚è±Ô∏è  Dur√©e totale: {total_duration}s")
        logger.info("=" * 60)
        
        return 0  # Code de succ√®s
        
    except Exception as e:
        logger.error(f"\n‚ùå ERREUR LORS DU CHARGEMENT: {e}")
        
        if connection:
            log_execution(connection, 'load', 'failed', error=str(e))
        
        return 1  # Code d'erreur
        
    finally:
        if connection:
            connection.close()
        if engine:
            engine.dispose()


if __name__ == "__main__":
    # Parser les arguments de ligne de commande
    parser = argparse.ArgumentParser(description='Chargement des donn√©es dans MySQL')
    parser.add_argument('--input-cross', type=str, help='Fichier CSV des cross-pairs')
    parser.add_argument('--input-ytd', type=str, help='Fichier CSV des m√©triques YTD')
    
    args = parser.parse_args()
    
    # Ex√©cution
    exit_code = main(
        input_cross_path=args.input_cross,
        input_ytd_path=args.input_ytd
    )
    
    sys.exit(exit_code)